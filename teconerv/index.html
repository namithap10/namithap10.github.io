<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos">
  <meta name="keywords" content="video compression, implicit neural representations, INR, NeRV, hypernetwork">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

</head>

<body>

  <!-- Hero / Title Section -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              TeCoNeRV: Leveraging Temporal Coherence for
              Compressible Neural Representations for Videos
            </h1>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://namithap10.github.io/">Namitha Padmanabhan</a>,
              </span>
              <span class="author-block">
                <a href="https://mgwillia.github.io/">Matthew Gwilliam</a>,
              </span>
              <span class="author-block">
                <a href="http://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">University of Maryland, College Park</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2602.16711" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fas fa-file-pdf"></i></span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/namithap10/TeCoNeRV/" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon"><i class="fab fa-github"></i></span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser Figure -->
  <section class="section" style="padding-top: 0;">
    <div class="container is-widescreen has-text-centered">

      <video src="static/videos/website_bosphore_sync_fps120.mp4" autoplay loop muted playsinline preload="auto"
        style="max-width: 1100px; width: 100%;">
      </video>
      <!-- border-radius: 6px; -->

      <p class="has-text-centered"
        style="max-width: 1100px; width: 100%; margin: 1rem auto 0; padding: 0 0.75rem; box-sizing: border-box; color: #4a4a4a; white-space: normal; overflow-wrap: anywhere; word-break: normal;">
        <b>TeCoNeRV enables temporally coherent weight updates for implicit video compression.</b>
        <!-- <b>TeCoNeRV enforces temporally coherent weight evolution across video clips.</b> -->
        As video content evolves over time (left), TeCoNeRV produces smooth clip-to-clip weight residuals (right),
        in contrast to the baseline (NeRV-Enc&nbsp;[1]) whose residual magnitudes fluctuate significantly.
        This temporal coherence enables more efficient compression while preserving visual quality.
        TeCoNeRV is the first hypernetwork-based implicit video compression method that scales to 720p and 1080p, while
        maintaining fast encoding speeds.
      </p>

    </div>
  </section>

  <!-- TL;DR -->
  <!-- <section class="section" style="padding-top: 0;">
    <div class="container is-max-desktop">
      <h2 class="subtitle has-text-centered">
        <b>TL;DR:</b> TeCoNeRV is the first hypernetwork-based implicit video compression method to scale to 720p and 1080p, 
        achieving better reconstruction quality over the baseline with lower bitrate while maintaining fast encoding speeds.
      </h2>
    </div>
  </section> -->

  <!-- Key Advantages -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Key Advantages</h2>
      <div class="columns is-multiline">
        <div class="column is-3">
          <div class="advantage-box">
            <span class="icon-text">
              <span class="icon has-text-info"><i class="fas fa-memory"></i></span>
              <span class="title is-5">Memory Reduction</span>
            </span>
            <p>Patch-tubelet decomposition decouples memory from resolution, enabling training on standard GPUs.</p>
          </div>
        </div>
        <div class="column is-3">
          <div class="advantage-box">
            <span class="icon-text">
              <span class="icon has-text-info"><i class="fas fa-bolt"></i></span>
              <span class="title is-5">Faster Encoding</span>
            </span>
            <p>1.5-3× faster encoding compared to baseline NeRV-Enc, with no per-video optimization required.</p>
          </div>
        </div>
        <div class="column is-3">
          <div class="advantage-box">
            <span class="icon-text">
              <span class="icon has-text-info"><i class="fas fa-compress"></i></span>
              <span class="title is-5">Lower Bitrate</span>
            </span>
            <p>Temporal coherence regularization produces highly compressible weight residuals, with nearly 40% lower
              bitrates.</p>
          </div>
        </div>
        <div class="column is-3">
          <div class="advantage-box">
            <span class="icon-text">
              <span class="icon has-text-info"><i class="fas fa-expand-arrows-alt"></i></span>
              <span class="title is-5">Resolution Independence</span>
            </span>
            <p>Train at 480p, inference at 720p or 1080p. No high-resolution training data required.</p>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3 has-text-centered">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Implicit Neural Representations (INRs) have recently demonstrated impressive performance for
              video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining
              encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos
              at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental
              limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking
              short video segments into <em>patch tubelets</em>, to reduce the pretraining memory overhead by 20×;
              (2) a <em>residual-based</em> storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a
              <em>temporal coherence regularization</em> framework that encourages changes in the weight space to be correlated with video content. Our proposed method,
              TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3× faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV.
              the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3× faster encoding speeds.
              With our low memory usage, we are the first hypernetwork-based approach to demonstrate results at 480p,
              720p and 1080p on UVG, HEVC, and MCL-JCV.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>


  <!-- Method -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Method</h2>

      <div class="has-text-centered">
        <img src="static/images/method.png" alt="TeCoNeRV method overview" style="max-width: 100%;">
      </div>

      <br>

      <div class="content has-text-justified">
        <p>
          <!-- <b>Overview of TeCoNeRV.</b> -->
          <em>Above:</em> Hypernetworks from prior work predict weights for entire video frames at once,
          resulting in large base parameters and bitstream size. <em>Below:</em> Our approach, TeCoNeRV, with (a)
          patch-tubelets that decouple
          spatial resolution from memory requirements, (b) residual encoding that stores only weight differences across
          time steps,
          and (c) temporal coherence finetuning that regularizes weight differences. Together, these components achieve
          better
          compression efficiency and superior reconstruction quality.
        </p>
      </div>
    </div>
  </section>

  <!-- Results -->
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Results</h2>

      <!-- Main table -->
      <div class="has-text-centered" style="margin-bottom: 2rem;">
        <img src="static/images/table_1_results.png"
            alt="Main quantitative results"
            style="max-width: 1100px; width: 100%;">

        <p class="is-size-8" style="color:#4a4a4a; margin-top:0.75rem;">
          <b>Main quantitative results (PSNR/SSIM, bitrate, and encoding/decoding speed).</b>
          Our primary hypernetwork baseline is <b>NeRV-Enc</b> (from FastNeRV&nbsp;[1]).
          Since NeRV-Enc’s memory grows quickly with resolution and is OOM at 1080p,
          we report comparisons against NeRV&nbsp;[2] and HiNeRV&nbsp;[3] at 1080p.
        </p>
      </div>

      <!-- RD plot -->
      <div class="has-text-centered" style="margin-top: 0.5rem;">
        <img src="static/images/rd_plot.png"
            alt="Rate–distortion curves at 480p"
            style="width: 75%; max-width: 1100px;">

        <p class="is-size-8" style="color:#4a4a4a; margin-top:0.75rem;">
          <b>Rate–distortion at 480p.</b> PSNR vs. bitrate (bpp) on <b>UVG</b> (left) and <b>Kinetics-400</b> (right),
          comparing TeCoNeRV to NeRV-Enc.
        </p>
      </div>
    </div>
  </section>


  <!-- Qualitative Results -->
  <section class="section">
    <div class="container is-max-desktop">

      <!-- <h2 class="title is-5 has-text-centered" style="margin-top: 2.5rem;">
        Reconstructions at 480p (TeCoNeRV vs. NeRV-Enc, on UVG)
      </h2> -->

      <div class="has-text-centered">
        <img src="static/images/qual_480p_nervenc_teco.png"
            alt="480p qualitative comparison: NeRV-Enc vs TeCoNeRV"
            style="width: 100%;">
      </div>
      <!--  style="margin-bottom: 2rem;" -->
      <p class="is-size-8 has-text-centered" style="color:#4a4a4a; margin-top: 0.5rem; margin-bottom: 1.25rem;">
        Visual comparison of <b>reconstruction quality at 480p</b> (TeCoNeRV vs. NeRV-Enc, on UVG).
      </p>

      <h2 class="title is-5 has-text-centered" style="margin-top: 2.5rem;">
        Video reconstructions of TeCoNeRV at higher resolutions
      </h2>

      <p class="is-size-7 has-text-centered" style="color:#4a4a4a; margin-top: 0.5rem; margin-bottom: 1.25rem;">
        NeRV-Enc is omitted at higher resolutions due to degraded quality at 720p and out-of-memory at 1080p.
      </p>

      <!-- Example 1 -->
      <div class="has-text-centered" style="margin-top: 1.25rem; margin-bottom: 2rem;">
        <p class="is-size-9" style="color:#4a4a4a; margin-bottom: 0.5rem;">
          <b>720p • Johnny (HEVC)</b>
           <!-- — TeCoNeRV reconstruction with overlapping patches + cropping. -->
        </p>

        <video src="static/videos/johnny_720p_overlap_crop.mp4"
              autoplay loop muted playsinline controls preload="auto"
              style="width: 55%; max-width: 100%; border-radius: 10px;">
        </video>
      </div>

      <!-- Example 2 -->
      <div class="has-text-centered" style="margin-top: 1.25rem; margin-bottom: 2rem;">
        <p class="is-size-9" style="color:#4a4a4a; margin-bottom: 0.5rem;">
          <b>1080p • Beauty (UVG)</b>
           <!-- — TeCoNeRV reconstruction with overlapping patches + blending. -->
        </p>

        <video src="static/videos/beauty_1080p_overlap_blend.mp4"
              autoplay loop muted playsinline controls preload="auto"
              style="width: 75%; max-width: 100%; border-radius: 10px;">
        </video>
      </div>

    </div>
  </section>



  <section class="section" id="References">
    <div class="container is-max-desktop">
      <h2 class="title is-3">References</h2>
      <div class="content">
        <ol>
          <li>
            Hao Chen et al.
            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/05618.pdf">Fast Encoding and Decoding for
              Implicit Video Representation</a>.
              In <i>ECCV</i>, 2024.
            </a>
          <li>
            Hao Chen et al.
            <a href="https://arxiv.org/pdf/2110.13903">NeRV: Neural Representations for Videos</a>.
            In <i>NeurIPS</i>, 2021.
          </li>
          <li>
            Ho Man Kwan et al.
            <a href="https://arxiv.org/pdf/2306.09818">HiNeRV: Video Compression with Hierarchical Encoding-based Neural Representation</a>.
            In <i>NeurIPS</i>, 2023.
          </li>
          </li>
        </ol>
      </div>
    </div>
  </section>



  <!-- BibTeX -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop">
      <h2 class="title is-3">BibTeX</h2>
      <!-- <p>If you find our work useful, please consider citing:</p> -->
      <div class="bibtex-box">
        <button class="copy-btn" onclick="copyBibtex()">
          <i class="far fa-copy"></i> Copy
        </button>
        <pre><code>
            @misc{padmanabhan2026teconervleveragingtemporalcoherence,
              title={TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos}, 
              author={Namitha Padmanabhan and Matthew Gwilliam and Abhinav Shrivastava},
              year={2026},
              eprint={2602.16711},
              archivePrefix={arXiv},
              primaryClass={cs.CV},
              url={https://arxiv.org/abs/2602.16711}, 
            }
        </code></pre>
      </div>
    </div>
  </section>


  <!-- Footer -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content has-text-centered">
            <p>
              The source code of this webpage is based on the <a
                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project webpage.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    // Resolution tab switching for results
    function showResults(resolution) {
      document.getElementById('results-480p').style.display = 'none';
      document.getElementById('results-720p').style.display = 'none';
      document.getElementById('results-1080p').style.display = 'none';
      document.getElementById('results-' + resolution).style.display = 'flex';

      // Update tabs - first set
      const tabs = document.querySelectorAll('.res-tabs')[0].querySelectorAll('.res-tab');
      tabs.forEach(tab => tab.classList.remove('is-active'));
      event.target.classList.add('is-active');
    }

    // Resolution tab switching for qualitative
    function showQual(resolution) {
      document.getElementById('qual-480p').style.display = 'none';
      document.getElementById('qual-720p').style.display = 'none';
      document.getElementById('qual-1080p').style.display = 'none';
      document.getElementById('qual-' + resolution).style.display = 'block';

      // Update tabs - second set
      const tabs = document.querySelectorAll('.res-tabs')[1].querySelectorAll('.res-tab');
      tabs.forEach(tab => tab.classList.remove('is-active'));
      event.target.classList.add('is-active');
    }

    // Copy BibTeX
    function copyBibtex() {
      const bibtex = document.querySelector('.bibtex-box pre code').textContent;
      navigator.clipboard.writeText(bibtex).then(() => {
        const btn = document.querySelector('.copy-btn');
        btn.innerHTML = '<i class="fas fa-check"></i> Copied!';
        setTimeout(() => {
          btn.innerHTML = '<i class="far fa-copy"></i> Copy';
        }, 2000);
      });
    }
  </script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

</body>

</html>